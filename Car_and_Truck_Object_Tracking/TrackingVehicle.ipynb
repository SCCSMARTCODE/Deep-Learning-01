{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12FbE0hffAG-CqQ1gjPhkKdHopd5dGssQ",
      "authorship_tag": "ABX9TyMbN+75PP1GoZYitA84D2Wv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SCCSMARTCODE/Deep-Learning-01/blob/main/Car_and_Truck_Object_Tracking/TrackingVehicle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîß **Project Setup and Environment**\n",
        "- [x] Install necessary libraries and dependencies:\n",
        "  - [x] Install **Ultralytics YOLOv8** with `pip install ultralytics`\n",
        "  - [x] Install **OpenCV** with `pip install opencv-python`\n",
        "  - [x] Install **Deep SORT** tracker and dependencies\n",
        "\n",
        "### üìÇ **Data Preparation**\n",
        "- [x] Download or create a simple vehicle dataset (if fine-tuning YOLOv8 is needed):\n",
        "  - [x] Label the dataset in **YOLO format** (class, x_center, y_center, width, height).\n",
        "  - [x] Use tools like **LabelImg** or **Roboflow** for labeling if needed.\n",
        "\n",
        "### üèó **Model Fine-Tuning with YOLOv8**\n",
        "- [x] Load the **YOLOv8 pre-trained model** (e.g., `yolov8n.pt` or `yolov8s.pt`).\n",
        "- [x] Fine-tune the model on your vehicle dataset:\n",
        "  - [x] Prepare the dataset in the YOLOv8 compatible format.\n",
        "  - [x] Use the Ultralytics API or command-line tool to fine-tune:\n",
        "    - Command example: `yolo task=detect mode=train model=yolov8n.pt data=your_dataset.yaml epochs=50 imgsz=640`\n",
        "  - [x] Check **training metrics** (loss, mAP) to validate improvements.\n",
        "- [x] Save the fine-tuned model for inference.\n",
        "\n",
        "### üñº **Video Inference and Object Detection**\n",
        "- [x] Load the fine-tuned YOLOv8 model\n",
        "\n",
        "### üöó **Integrate Deep SORT for Object Tracking**\n",
        "\n",
        "- [x] Draw bounding boxes and track IDs on the video frames using OpenCV.\n",
        "\n",
        "### üîÑ **Real-Time Video Processing (Optional)**\n",
        "\n",
        "### üé• **Saving Output Video (Optional)**\n",
        "\n",
        "### ‚öôÔ∏è **Additional Enhancements**\n",
        "- [x] Tune **Deep SORT parameters** (e.g., `max_age`, `min_confidence`) for improved tracking performance.\n",
        "- [ ] Implement **NMS (Non-Maximum Suppression)** to handle overlapping bounding boxes if necessary.\n",
        "- [x] Add vehicle **speed estimation** or **counting** if required for your project.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nbAE5VD_yrWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTTPoew-tk3k"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install deep-sort-realtime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort"
      ],
      "metadata": {
        "id": "NnxVZPj8E2Y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0071c18d-03ff-4c92-b1dc-21907390fcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model = \"/content/drive/MyDrive/Deep_Learning/Vehicle_Tracking/saved_model.pt\"\n",
        "model = YOLO(fine_tuned_model)"
      ],
      "metadata": {
        "id": "r9oHYyxPE6c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Deep_Learning/Vehicle_Tracking/CarsTrucksDetection.v6i.yolov8.zip\""
      ],
      "metadata": {
        "id": "1Wsty8-nF82X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(\n",
        "    data=\"/content/data.yaml\",\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    cos_lr=True,\n",
        "    batch=64,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "3vXitT_PGHEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "50 epochs completed in 0.312 hours.\n",
        "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
        "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
        "\n",
        "Validating runs/detect/train/weights/best.pt...\n",
        "Ultralytics YOLOv8.2.101 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
        "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
        "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s]\n",
        "                   all        100        294      0.798      0.788      0.837      0.533\n",
        "                   Car         43        142      0.758       0.81      0.825      0.499\n",
        "                 Plate         37         48      0.747      0.708      0.772      0.438\n",
        "                 Truck         74        104      0.889      0.846      0.913      0.662\n",
        "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
        "Results saved to runs/detect/train\n",
        "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
        "\n",
        "ap_class_index: array([0, 1, 2])\n",
        "box: ultralytics.utils.metrics.Metric object\n",
        "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7d5dec0e6680>\n",
        "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
        "```"
      ],
      "metadata": {
        "id": "lQs8QNiw3KWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.val()"
      ],
      "metadata": {
        "id": "VEnTMa-sM-3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "\n",
        "Ultralytics YOLOv8.2.101 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
        "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
        "val: Scanning /content/valid/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<?, ?it/s]\n",
        "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.43s/it]\n",
        "                   all        100        294      0.796      0.789      0.836      0.532\n",
        "                   Car         43        142      0.755       0.81      0.825      0.495\n",
        "                 Plate         37         48      0.743      0.708      0.771      0.439\n",
        "                 Truck         74        104      0.889      0.848      0.913      0.663\n",
        "Speed: 0.3ms preprocess, 4.9ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
        "Results saved to runs/detect/train2\n",
        "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
        "\n",
        "ap_class_index: array([0, 1, 2])\n",
        "box: ultralytics.utils.metrics.Metric object\n",
        "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7d5df2578910>\n",
        "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
        "```"
      ],
      "metadata": {
        "id": "n4MhmUoO3eLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def network_inference(input_path: str = \"inference_video.mp4\",\n",
        "                      output_path: str = \"output_video5.mp4\"):\n",
        "    tracker = DeepSort(max_age=30, n_init=3)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    model_input_size = (640, 640)\n",
        "\n",
        "    while True:\n",
        "        isTrue, frame = cap.read()\n",
        "        if not isTrue:\n",
        "            break\n",
        "\n",
        "        resized_frame = cv2.resize(frame, model_input_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        results = model(resized_frame)\n",
        "\n",
        "        boxes = results[0].boxes.xyxy\n",
        "        class_ids = results[0].boxes.cls\n",
        "        confidences = results[0].boxes.conf\n",
        "\n",
        "        detections = []\n",
        "        car_count = 0\n",
        "        truck_count = 0\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            confidence = confidences[i]\n",
        "            class_id = int(class_ids[i])\n",
        "\n",
        "            if confidence < 0.5:\n",
        "                continue\n",
        "\n",
        "            if class_id == 0:\n",
        "                car_count += 1\n",
        "            elif class_id == 2:\n",
        "                truck_count += 1\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            bbox = [x1, y1, x2 - x1, y2 - y1]\n",
        "            detections.append((bbox, confidence, class_id))\n",
        "\n",
        "        tracks = tracker.update_tracks(detections, frame=resized_frame)\n",
        "\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "\n",
        "            track_id = track.track_id\n",
        "            ltrb = track.to_ltwh()\n",
        "            x1, y1, w, h = map(int, ltrb)\n",
        "\n",
        "            class_id = track.det_class\n",
        "            color = (0, 255, 0) if class_id == 0 else (255, 0, 0)\n",
        "\n",
        "            cv2.rectangle(resized_frame, (x1, y1), (x1 + w, y1 + h), color, 2)\n",
        "\n",
        "            cv2.putText(resized_frame, f\"ID {track_id} | {confidence:.2f}\", (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "        text = f\"Cars: {car_count} | Trucks: {truck_count}\"\n",
        "        cv2.putText(resized_frame, text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        output_frame = cv2.resize(resized_frame, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        out.write(output_frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(f\"Video saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "3aQXzQJKXnZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_inference()"
      ],
      "metadata": {
        "id": "jCqKoZw5a4ic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}